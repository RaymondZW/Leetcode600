{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to wait for a huge number of network events efficientsly. \n",
    "# (asynchronous I/O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waits for many responses, but does little computation\n",
    "# If it devotes a thread to each in-flight request, then as the number of \n",
    "# concurrent requests rises, it will run out of memory or other\n",
    "# thread-related resource before it runs out of sockets.\n",
    "\n",
    "# It avoids the need for threads by using async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. show an async event loop, sketch a crawler that uses event loop with\n",
    "# callbacks. \n",
    "\n",
    "# 2. python coroutines are both efficient and extensible. \n",
    "# We implement coroutines in Python using generators.\n",
    "\n",
    "# 3. We use Python's standard 'asyncio' library, and corrdinate coroutines\n",
    "# using an async queue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A crawler finds and downloads all pages on a website, perhaps to archive\n",
    "# or index them. Beginning with a root URL, it fetches each page, parses it\n",
    "# for links to unseen pages, and adds theses to a queue. It stops when it \n",
    "# fetches a page with no unseen links and the queue is empty\n",
    "\n",
    "# We can hasten this process by downloading many pages concurrently.\n",
    "# AS the crawler finds new links, it launches simultaneous fetch operation\n",
    "# on separate sockets. It parses responses as they arrive, adding new links\n",
    "# to the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'parse_links'",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-24e1d09bbdf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'parse_links'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import socket, parse_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'xkcd.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sock = socket.socket()\n",
    "sock.connect(('xkcd.com', 80))\n",
    "request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(url)\n",
    "sock.send(request.encode('ascii'))\n",
    "response = b''\n",
    "chunk = sock.recv(4096)\n",
    "while chunk:\n",
    "    response += chunk\n",
    "    chunk = sock.recv(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GET xkcd.com HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditionally, we createa thread pool. \n",
    "def fetch(url):\n",
    "    sock = socket.socket()\n",
    "    sock.connect(('xkcd.com', 80))\n",
    "    request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(url)\n",
    "    sock.send(request.encode('ascii'))\n",
    "    response = b''\n",
    "    chunk = sock.recv(4096)\n",
    "    while chunk:\n",
    "        response += chunk\n",
    "        chunk = sock.recv(4096)\n",
    "        \n",
    "    # Page is now downloaded.\n",
    "    links = parse_links(response)\n",
    "    q.add(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_links' is not defined",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-52efd72f8a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xkcd.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c342abbfd83b>\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Page is now downloaded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_links' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "fetch('xkcd.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sock = socket.socket()\n",
    "sock.setblocking(False)\n",
    "try:\n",
    "    sock.connect(('xkcd.com', 80))\n",
    "except BlockingIOError:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<socket.socket fd=61, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.14.48.212', 61550), raddr=('151.101.192.67', 80)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irritatingly, a non-blocking socket throws an exception from connect, \n",
    "# even hwne it is working normally. This exception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent\n"
     ]
    }
   ],
   "source": [
    "request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(url)\n",
    "encoded = request.encode('ascii')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        sock.send(encoded)\n",
    "        break\n",
    "    except OSError as e:\n",
    "        pass\n",
    "\n",
    "print('sent')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectorKey(fileobj=60, fd=60, events=2, data=<function connected at 0x10a2fdf28>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 3.4's DefaultSElector uses the best select like function.\n",
    "\n",
    "from selectors import DefaultSelector, EVENT_WRITE\n",
    "\n",
    "selector = DefaultSelector()\n",
    "sock = socket.socket()\n",
    "sock.setblocking(False)\n",
    "\n",
    "try:\n",
    "    sock.connect(('xkcd.com', 80))\n",
    "except BlockingIOError:\n",
    "    pass\n",
    "\n",
    "def connected():\n",
    "    selector.unregister(sock.fileno())\n",
    "    print('connected!')\n",
    "    \n",
    "selector.register(sock.fileno(), EVENT_WRITE, connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop():\n",
    "    while True:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connected call back is stored as event_key.data which ew retrive adn exec once\n",
    "# the none blocking socket is connected.\n",
    "\n",
    "# unlike in our fast spinning loop above, the call to select here pauses, awaiting the next I/O events.\n",
    "# Then the loop runs callbacks that are waiting for these events\n",
    "\n",
    "# We built a tiny system that does overlapping I/O. It doesn't actually utilize\n",
    "# multiple cores to execute computation in parallel. But then, \n",
    "\n",
    "# So "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the runty framework we have built so far, how can we bild a web crawler\n",
    "# we begin with global sets of the urls we have yet to fetch, and the urls we\n",
    "# have seen:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_todo = set(['/'])\n",
    "seen_urls = set(['/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetching a page will require a series of callbacks. the connected callback\n",
    "fies when a socket is connected, and sends a get request ot the server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    def __init__(self, url):\n",
    "        self.response = b''\n",
    "        self.url = url\n",
    "        self.sock = None\n",
    "    \n",
    "    def fetch(self):\n",
    "        self.sock = socket.socket()\n",
    "        self.sock.setblocking(False)\n",
    "        \n",
    "        try:\n",
    "            self.sock.connect(('xkcd.com', 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "        \n",
    "        selector.register(self.sock.fileno(), \n",
    "                         EVENT_WRITE,\n",
    "                         self.connected)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Interpretor Lock\n",
    "# GIL\n",
    "\n",
    "import sys\n",
    "a = []\n",
    "b = a\n",
    "c = b\n",
    "d = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getrefcount(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getrefcount(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time in sec:  8.432587146759033\n"
     ]
    }
   ],
   "source": [
    "# CPU-bound program\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "COUNT = 50000000\n",
    "\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "        \n",
    "start = time.time()\n",
    "countdown(COUNT)\n",
    "end = time.time()\n",
    "\n",
    "print('time in sec: ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.159382104873657\n"
     ]
    }
   ],
   "source": [
    "# Multithreaded Python (with GIL)\n",
    "\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "COUNT = 50000000\n",
    "\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "        \n",
    "t1 = Thread(target = countdown, args=(COUNT//2,))\n",
    "t2 = Thread(target = countdown, args=(COUNT//2,))\n",
    "\n",
    "start = time.time()\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((COUNT//2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin_list = ['111', '222', '333', '444', '555', '666', '222']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "q = Queue(maxsize=0)\n",
    "\n",
    "results = [{} for x in vin_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{}, {}, {}, {}, {}, {}, {}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multithreading for vin decoding\n",
    "# num_theads = 200\n",
    "num_theads = 500\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "from threading import Thread\n",
    "# Setting up the Queue\n",
    "from queue import Queue\n",
    "#set up the queue to hold all the urls\n",
    "q = Queue(maxsize=0)\n",
    "# Use many threads (50 max, or one for each url)\n",
    "\n",
    "#Populating Queue with tasks\n",
    "# results_full = [{} for x in vin_list]\n",
    "results = [{} for x in vin_list]\n",
    "results_full = copy.deepcopy(results)\n",
    "# results_full = [{} for x in vin_list]\n",
    "\n",
    "#load up the queue with the urls to fetch and the index for each job (as a tuple):\n",
    "for i in range(len(vin_list)):\n",
    "    #need the index and the url in each queue item.\n",
    "    q.put((i,vin_list[i]))\n",
    "    \n",
    "    \n",
    "# Threaded function for queue processing.\n",
    "def vin_lu_threaded(q, result):\n",
    "    while not q.empty():\n",
    "        i,vin = q.get()                      #fetch new work from the Queue\n",
    "        try:\n",
    "            url = 'https://vin-decoder.dev.pod.tc/decode/vipr'\n",
    "            payload = {\"vin\":vin}\n",
    "            headers = {'Content-Type': 'application/json','Accept': 'application/json','token': '123'}\n",
    "            r = requests.post(url, data=json.dumps(payload), headers=headers)   \n",
    "            r_json = r.json()\n",
    "            make,model,year,chromeStyleId = \\\n",
    "            r_json['make'].upper(),r_json['model'].upper(),r_json['modelYear'],r_json['chromeStyleId']\n",
    "            results[i] = (make,model,year,chromeStyleId)  #Store data back at correct index\n",
    "            results_full[i] = tuple([r_json[x] for x in ['viprMakeId', 'viprModelId', 'viprStyleId']])\n",
    "        except:\n",
    "            result[i] = ('','',0)\n",
    "        #signal to the queue that task has been processed\n",
    "        q.task_done()\n",
    "    return True\n",
    "\n",
    "#Starting worker threads on queue processing\n",
    "for i in range(num_theads):\n",
    "    logging.debug('Starting thread ', i)\n",
    "    worker = Thread(target=vin_lu_threaded, args=(q,results))\n",
    "    worker.setDaemon(True)    #setting threads as \"daemon\" allows main program to \n",
    "                              #exit eventually even if these dont finish \n",
    "                              #correctly.\n",
    "    worker.start()\n",
    "#now we wait until the queue has been processed\n",
    "q.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
